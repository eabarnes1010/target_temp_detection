{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da79c16-eb43-4664-a883-7a31f3af00da",
   "metadata": {
    "id": "4a650402-4774-49cb-9b72-9c8f1dd02f1d",
    "tags": []
   },
   "source": [
    "# Detecting temperature targets\n",
    "##### authors: Elizabeth A. Barnes and Noah Diffenbaugh\n",
    "##### date: March 20, 2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccff821-b304-4009-8fe8-75a213b3f421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Python stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb968382-4186-466e-a85b-b00caa5fc9be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17642,
     "status": "ok",
     "timestamp": 1646449680995,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "fb968382-4186-466e-a85b-b00caa5fc9be",
    "outputId": "d7964af9-2d52-4466-902d-9b85faba9a91",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Softmax\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "\n",
    "import experiment_settings\n",
    "import file_methods\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"figure.dpi\"] = 150\n",
    "savefig_dpi = 300\n",
    "np.warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5cee3-6f4f-4818-92e1-1351eeeb565a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1646449681009,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "29a5cee3-6f4f-4818-92e1-1351eeeb565a",
    "outputId": "e5f5b0ac-82b8-4147-bf44-4bc3b49466a2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"xarray version = {xr.__version__}\")  \n",
    "print(f\"tensorflow version = {tf.__version__}\")  \n",
    "print(f\"tensorflow-probability version = {tfp.__version__}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651315ce-eecc-4d30-8b90-c97d08936315",
   "metadata": {},
   "source": [
    "## User Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a544f-ef35-417f-bec4-62225d885014",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'exp0'\n",
    "exp_settings = experiment_settings.get_settings(EXP_NAME)\n",
    "display(exp_settings)\n",
    "\n",
    "\n",
    "MODEL_DIRECTORY = 'saved_models/'        \n",
    "FILE_DIRECTORY = 'saved_files/'\n",
    "DATA_DIRECTORY = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d089c5-afe9-4d5c-93d1-b67662256c1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the data and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eea0ec-ce97-469e-b7d6-da1fa0863927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filenames = file_methods.get_cmip_filenames(exp_settings)\n",
    "N_GCMS = len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be3a1a6-74cf-44e3-abf6-2088cbea8e73",
   "metadata": {},
   "source": [
    "## Load the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13226df-3764-402e-a6be-9e6ea3d3d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs, global_mean_obs = data_processing.get_observations(exp_settings)\n",
    "N_TRAIN, N_VAL, N_TEST, ALL_MEMBERS = data_processing.get_members(exp_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf95abe-3856-45d6-9204-6cb9bad3dfaf",
   "metadata": {
    "id": "6bf95abe-3856-45d6-9204-6cb9bad3dfaf",
    "tags": []
   },
   "source": [
    "## Network and XAI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2587a9c-7d17-4744-b4b2-f7781815ef2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                   patience=exp_settings['patience'],\n",
    "                                                   verbose=1,\n",
    "                                                   mode='auto',\n",
    "                                                   restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c807abd7-832a-484b-98cd-7e6c3a9f60c0",
   "metadata": {
    "id": "c807abd7-832a-484b-98cd-7e6c3a9f60c0",
    "tags": []
   },
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7becb266-c9fd-4098-a2ba-e6c52804b8bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 962
    },
    "executionInfo": {
     "elapsed": 105064,
     "status": "ok",
     "timestamp": 1646449809976,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "7becb266-c9fd-4098-a2ba-e6c52804b8bd",
    "outputId": "5f2d4b54-fb88-418f-95a2-3c5e281cc2e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(exp_settings[\"rng_seed\"])\n",
    "pred_obs_vec = np.zeros(shape=(exp_settings['n_models'], x_obs.shape[0], 2))*np.nan\n",
    "\n",
    "for iloop in np.arange(exp_settings['n_models']):\n",
    "    SEED = rng.integers(low=1_000,high=10_000,size=1)[0]    \n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    train_members = rng.choice(ALL_MEMBERS, size=N_TRAIN, replace=False)\n",
    "    val_members   = rng.choice(np.setdiff1d(ALL_MEMBERS,train_members), size=N_VAL, replace=False)\n",
    "    test_members  = rng.choice(np.setdiff1d(ALL_MEMBERS,np.append(train_members[:],val_members)), size=N_TEST, replace=False)\n",
    "    print(train_members, val_members, test_members)\n",
    "\n",
    "    (x_train, \n",
    "     x_val, \n",
    "     x_test, \n",
    "     y_train, \n",
    "     y_val, \n",
    "     y_test, \n",
    "     onehot_train, \n",
    "     onehot_val, \n",
    "     onehot_test, \n",
    "     y_yrs_train, \n",
    "     y_yrs_val, \n",
    "     y_yrs_test, \n",
    "     target_years, \n",
    "     map_shape) = data_processing.get_cmip_data(exp_settings)\n",
    "\n",
    "    #----------------------------------------        \n",
    "    tf.keras.backend.clear_session()                \n",
    "    model = compile_model()\n",
    "    history = model.fit(x_train, onehot_train, \n",
    "                        epochs=exp_settings['n_epochs'], \n",
    "                        verbose=exp_settings['verbosity'],\n",
    "                        batch_size = exp_settings['batch_size'], \n",
    "                        shuffle=True,\n",
    "                        validation_data=[x_val, onehot_val],\n",
    "                        callbacks=[early_stopping,],\n",
    "                       )\n",
    "    #----------------------------------------\n",
    "    # create predictions for observations with this model\n",
    "    pred_obs = model.predict(x_obs)\n",
    "    pred_obs_vec[iloop,:,:pred_obs.shape[1]] = pred_obs\n",
    "    \n",
    "    #----------------------------------------\n",
    "    # save the tensorflow model\n",
    "    model_name = files.get_model_name()\n",
    "    if exp_settings[\"save_model\"]:\n",
    "        save_tf_model(model, model_name)\n",
    "        save_pred_obs(pred_obs_vec, model_name[:model_name.rfind('_seed')] + '_pred_obs')\n",
    "    \n",
    "    #----------------------------------------\n",
    "    if exp_settings[\"show_plots\"]:\n",
    "       \n",
    "        plt.plot(history.history['loss'], label='loss')\n",
    "        plt.plot(history.history['val_loss'], label='val_loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635d170-ee55-4c82-8519-93b2565fcd5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make loss plots following training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0f89f-a5b7-4e32-bae4-4f0f9efa73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_settings[\"network_type\"] == 'shash2':\n",
    "    try:\n",
    "        imin = len(history.history['custom_mae'])\n",
    "        plt.subplots(figsize=(20,4))\n",
    "\n",
    "        plt.subplot(1,4,1)\n",
    "        plot_metrics(history,'loss')\n",
    "        plt.ylim(0,10.)\n",
    "\n",
    "        plt.subplot(1,4,2)\n",
    "        plot_metrics(history,'custom_mae')\n",
    "        plt.ylim(0,10)\n",
    "\n",
    "        plt.subplot(1,4,3)\n",
    "        plot_metrics(history,'interquartile_capture')\n",
    "\n",
    "        plt.subplot(1,4,4)\n",
    "        plot_metrics(history,'sign_test')\n",
    "\n",
    "        plt.show()\n",
    "    except:\n",
    "        print('metrics were not saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647acbe8-c4f3-428a-95ca-e40373ec1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_settings['network_type'] == \"shash2\":\n",
    "    top_pred_idx = 0\n",
    "else:\n",
    "    top_pred_idx = None\n",
    "    \n",
    "YEARS_UNIQUE = np.unique(y_yrs_train)\n",
    "predict_train = model.predict(x_train)[:,top_pred_idx].flatten()\n",
    "predict_val = model.predict(x_val)[:,top_pred_idx].flatten()\n",
    "mae = np.mean(np.abs(predict_val-y_val[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b05d0-da60-4eda-86b7-4327333093c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "executionInfo": {
     "elapsed": 990,
     "status": "ok",
     "timestamp": 1646449810953,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "156b05d0-da60-4eda-86b7-4327333093c1",
    "outputId": "6d37c46a-c8a3-4e44-df23-edd7e9b38697",
    "tags": []
   },
   "outputs": [],
   "source": [
    "clr = ('tab:purple','tab:orange', 'tab:blue', 'tab:green', 'gold', 'brown','black','darkorange')\n",
    "#--------------------------------\n",
    "plt.subplots(1,2,figsize=(15,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(y_train, predict_train,'.',color='gray',alpha=.5, label='training')\n",
    "plt.plot(y_val, predict_val,'.', label='validation')\n",
    "plt.plot(y_val,y_val,'--',color='fuchsia')\n",
    "plt.axvline(x=0,color='gray',linewidth=1)\n",
    "plt.axhline(y=0,color='gray',linewidth=1)\n",
    "plt.title('Validation MAE = ' + str(mae.round(2)) + ' years')\n",
    "plt.xlabel('true number of years until target is reached')\n",
    "plt.ylabel('predicted number of years until target is reached')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(y_yrs_train, predict_train,'.',color='gray',alpha=.5, label='training')\n",
    "plt.title('Time to Target Year for ' + str(exp_settings['target_temp']) + 'C using ssp' + str(exp_settings['ssp']))\n",
    "plt.xlabel('year of map')\n",
    "plt.ylabel('predicted number of years until target is reached')\n",
    "plt.axhline(y=0, color='gray', linewidth=1)\n",
    "\n",
    "predict_val_mat = predict_val.reshape(N_GCMS,N_VAL,len(YEARS_UNIQUE))\n",
    "for i in np.arange(0,predict_val_mat.shape[0]):\n",
    "    plt.plot(YEARS_UNIQUE, predict_val_mat[i,:,:].swapaxes(1,0),'.', label='validation', color=clr[i])\n",
    "    plt.axvline(x=target_years[i],linestyle='--',color=clr[i])\n",
    "if IN_COLAB==False:\n",
    "    pass\n",
    "    # plt.savefig('figures/initial_result_seed' + str(SEED) + '.png', dpi=savefig_dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ad419-afcc-4ab8-8a4a-d5cb3ca15c78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predict observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe28ad8-862a-401c-97c1-f8eb44f05038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predict_obs = model.predict(x_obs)[:,top_pred_idx].flatten()\n",
    "\n",
    "iy = np.where(da_obs['time.year'].values >= 2001)[0]\n",
    "x = da_obs['time.year'].values[iy]\n",
    "y = y_predict_obs[iy]\n",
    "linear_model = stats.linregress(x=x,y=y)\n",
    "\n",
    "#--------------------------------\n",
    "i_year = np.where(y_predict_obs < 0)[0]\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(da_obs['time.year'], y_predict_obs, '.r')\n",
    "plt.plot(x, linear_model.slope*x+linear_model.intercept, '--k', alpha=.5, linewidth=2)\n",
    "plt.xlabel('year of map')\n",
    "plt.ylabel('predicted number of years \\nuntil target is reached')\n",
    "plt.title(exp_settings[\"obsdata\"] + ' Target Year for ' + str(exp_settings['target_temp']) + 'C using ssp' + str(exp_settings['ssp']) + ' = ' + \n",
    "          str(np.round(2021+y_predict_obs[-1],1)) +\n",
    "          ' (' + str(y_predict_obs[-1].round()) + ' years)'+\n",
    "          '\\n slope = ' + str(linear_model.slope.round(2)) \n",
    "         )\n",
    "plt.xlim(1970,2025)\n",
    "plt.ylim(-10,80)\n",
    "plt.axhline(y=0,color='gray')\n",
    "\n",
    "#--------------------------------\n",
    "plt.subplot(1,2,2)\n",
    "global_mean_obs.plot(linewidth=2,label='data',color=\"tab:orange\")\n",
    "plt.title(exp_settings[\"obsdata\"] + ' Observations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e3dd0-7bd4-4271-8af1-850cb1aee64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 4\n",
    "grads_obs = get_gradients(x_obs[-n_plot:,:],top_pred_idx=top_pred_idx).numpy()*x_obs[-n_plot:,:]\n",
    "print('np.shape(grads_obs) = ' + str(np.shape(grads_obs)))\n",
    "grads_obs_mean = np.mean(grads_obs,axis=0)\n",
    "plt.figure(figsize=(10,4))\n",
    "plot_map(grads_obs_mean.reshape((map_shape[0],map_shape[1])), \n",
    "         clim = (-.02,.02),\n",
    "         title = 'Observations ' + str(2021-n_plot+1) + '-' + str(2021) + ': Gradient x Input',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f952d05-2b3d-4705-91a9-1deb752591fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "if exp_settings[\"network_type\"] == 'shash2':\n",
    "\n",
    "    clr_choice = 'orange'\n",
    "    y_predict_obs = model.predict(x_obs)\n",
    "\n",
    "    iy = np.where(da_obs['time.year'].values >= 2011)[0]\n",
    "    x = da_obs['time.year'].values[iy]\n",
    "    y = y_predict_obs[iy,0]\n",
    "    linear_model = stats.linregress(x=x,y=y)\n",
    "\n",
    "    #--------------------------------\n",
    "    norm_incs = np.arange(-80,80,1)\n",
    "    mu_pred = y_predict_obs[:,0]\n",
    "    sigma_pred = y_predict_obs[:,1]\n",
    "    norm_dist = tfp.distributions.Normal(mu_pred,sigma_pred)\n",
    "    norm_perc_low = norm_dist.quantile(.25).numpy()   \n",
    "    norm_perc_high = norm_dist.quantile(.75).numpy()      \n",
    "    norm_perc_med = norm_dist.quantile(.5).numpy()      \n",
    "    norm_cpd = norm_dist[-1].prob(norm_incs)\n",
    "    y_predict_obs = norm_perc_med\n",
    "    \n",
    "    print('2021 prediction = ' + str(mu_pred[-1]) + ' (' + str(norm_perc_low[-1]) + ' to ' + str(norm_perc_high[-1]) + ')')\n",
    "\n",
    "    #------------------------------------------------------------\n",
    "    ax = plt.subplots(1,2,figsize=(16,4))\n",
    "    years = np.arange(1850,2022)\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    for iyear in np.arange(0,y_predict_obs.shape[0]):\n",
    "        min_val = norm_perc_low[iyear]\n",
    "        max_val = norm_perc_high[iyear]\n",
    "\n",
    "        if(years[iyear]==2021):\n",
    "            clr = clr_choice\n",
    "        else:\n",
    "            clr = 'gray'\n",
    "        plt.plot((years[iyear],years[iyear]),(min_val, max_val),\n",
    "                 linestyle='-',\n",
    "                 linewidth=4,\n",
    "                 color=clr,\n",
    "                )\n",
    "\n",
    "    plt.plot(x,x*linear_model.slope+linear_model.intercept,'--', color='black')\n",
    "\n",
    "    plt.xlim(1970.5,2023)    \n",
    "    plt.ylim(-10,80)\n",
    "    plt.ylabel('years until target')\n",
    "    plt.xlabel('year')\n",
    "    plt.title(exp_settings[\"obsdata\"] + ' predictions for ' + str(exp_settings['target_temp']) + 'C using ssp' + exp_settings[\"ssp\"] + ' (norm)\\n slope=' + str(linear_model.slope.round(2)))\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(norm_incs,norm_cpd,\n",
    "             linewidth=5,\n",
    "             color=clr_choice,\n",
    "            )\n",
    "\n",
    "    k = np.argmin(np.abs(norm_perc_low[-1]-norm_incs))\n",
    "    plt.plot((norm_perc_low[-1],norm_perc_low[-1]),(0,norm_cpd[k]),'--',color=clr_choice)\n",
    "    k = np.argmin(np.abs(norm_perc_high[-1]-norm_incs))\n",
    "    plt.plot((norm_perc_high[-1],norm_perc_high[-1]),(0,norm_cpd[k]),'--',color=clr_choice)\n",
    "\n",
    "    plt.xlabel('years until target')\n",
    "    plt.title('Predictions for ' + exp_settings[\"obsdata\"] + ' Observations under SSP' + exp_settings[\"ssp\"] + '\\nYear = 2021')\n",
    "\n",
    "    if exp_settings[\"target_temp\"] == 1.1:\n",
    "        plt.xlim(-20,20)\n",
    "    elif exp_settings[\"target_temp\"] == 1.5:\n",
    "        plt.xlim(-10,40)\n",
    "    elif exp_settings[\"target_temp\"] == 2.0:\n",
    "        plt.xlim(-10,70)\n",
    "    else:\n",
    "        plt.xlim(-70,70)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ea61d-e514-415e-be5a-15b43367134f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Explainability via Input * Gradient and Integrated Gradients\n",
    "We will use two attribution explainaiblity methods called Input * Gradient and Integrated Gradients to make heatmaps of regions of the input that act as explanations for the network's prediction.\n",
    "\n",
    "* https://keras.io/examples/vision/integrated_gradients/\n",
    "* https://distill.pub/2020/attribution-baselines/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef431b-27ad-4874-959e-169e6f7f198c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#=========================================\n",
    "# Define the samples you want to explain\n",
    "rng = np.random.default_rng(45)\n",
    "isubsample = rng.choice(np.arange(0,x_val.shape[0]),\n",
    "                        size = 500,\n",
    "                        replace = False,\n",
    "                       )\n",
    "\n",
    "inputs = np.copy(x_val[isubsample,:])\n",
    "targets = np.copy(y_val[isubsample])\n",
    "yrs = np.copy(y_yrs_val[isubsample])\n",
    "preds = model.predict(inputs)\n",
    "\n",
    "#=========================================\n",
    "#---------------------------------------\n",
    "# Gradient x Input\n",
    "#---------------------------------------\n",
    "# compute the multiplication of gradient * inputs\n",
    "# and reshape into a map of latitude x longitude\n",
    "\n",
    "grads = get_gradients(inputs,top_pred_idx).numpy()\n",
    "grad_x_input = grads * inputs\n",
    "grad_x_input = grad_x_input.reshape((len(targets),map_shape[0],map_shape[1]))\n",
    "print(np.shape(grad_x_input))\n",
    "\n",
    "#---------------------------------------\n",
    "# Integrated Gradients\n",
    "#---------------------------------------\n",
    "baseline_mean = np.mean(x_train,axis=0)*0.    \n",
    "print('shape(baseline_mean) = ' + str(np.shape(baseline_mean)))\n",
    "print('model.predict(baseline_mean) = ' + str(model.predict(baseline_mean[np.newaxis,:])))\n",
    "\n",
    "igrad = get_integrated_gradients(inputs, baseline=baseline_mean,top_pred_idx=top_pred_idx)\n",
    "integrated_gradients = igrad.numpy().reshape((len(targets),map_shape[0],map_shape[1]))\n",
    "print(np.shape(integrated_gradients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c536cb-85e5-4b49-84ab-7de73aa82a25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# plot the resulting heatmaps for a subset of samples\n",
    "# based on their label\n",
    "plot_list = (40, 20, 10, 0)\n",
    "NCOL = 4\n",
    "plt.subplots(len(plot_list),NCOL,figsize=(35,5*len(plot_list)))\n",
    "\n",
    "for irow,min_range in enumerate(plot_list):\n",
    "        \n",
    "    max_range = min_range + 5\n",
    "    isamples = np.where((targets >= min_range) & (targets <= max_range))[0]\n",
    "    igrad_mean = np.mean(integrated_gradients[isamples,:,:],axis=0)\n",
    "    grad_x_input_mean = np.mean(grad_x_input[isamples,:,:],axis=0)\n",
    "    grad_mean = np.mean(grads[isamples,:],axis=0).reshape((map_shape[0],map_shape[1]))\n",
    "    x_inputs_mean = np.mean(inputs[isamples,:],axis=0).reshape((map_shape[0],map_shape[1]))\n",
    "    x_inputs_mean = x_inputs_mean - baseline_mean.reshape((map_shape[0],map_shape[1]))\n",
    "    #------------------------------------------------------------------\n",
    "    \n",
    "    text = (\n",
    "            \"\\n\"\n",
    "            + f\"  label_range    = {min_range}-{max_range} yrs.\\n\"                    \n",
    "            + f\"  n_samples      = {len(isamples)}\\n\"\n",
    "    )    \n",
    "    #------------------------------------------------------------------    \n",
    "    \n",
    "    # plot average input map\n",
    "    plt.subplot(len(plot_list),NCOL,irow*NCOL+1)\n",
    "    plot_map(x_inputs_mean, \n",
    "             text=text,\n",
    "             clim=(-5,5),\n",
    "             cmap='RdBu_r',\n",
    "             title = 'Temperature anomaly from Baseline',\n",
    "            )\n",
    "    #------------------------------------------------------------------\n",
    "    # plot explainability of gradient (saliency)\n",
    "    plt.subplot(len(plot_list),NCOL,irow*NCOL+2)\n",
    "    plot_map(grad_mean, \n",
    "             text=text,             \n",
    "             clim=(-0.02, .02), \n",
    "             title = 'Gradient (Saliency)',\n",
    "            )\n",
    "    \n",
    "    #------------------------------------------------------------------\n",
    "    # plot explainability of input x gradient\n",
    "    plt.subplot(len(plot_list),NCOL,irow*NCOL+3)\n",
    "    plot_map(grad_x_input_mean, \n",
    "             text=text,\n",
    "             clim=(-.02,.02),\n",
    "             title = 'Gradient x Input',\n",
    "            )\n",
    "\n",
    "    #------------------------------------------------------------------\n",
    "    # plot explainability of integrated gradients\n",
    "    plt.subplot(len(plot_list),NCOL,irow*NCOL+4)\n",
    "    plot_map(igrad_mean, \n",
    "             text=text,             \n",
    "             clim=(-.02,.02), \n",
    "             title = 'Integrated Gradients',\n",
    "            )\n",
    "\n",
    "plt.tight_layout()   \n",
    "# plt.savefig('figures/xai_grid_' + str(min_range) +'-' + str(max_range) + '_baseline_' + str(BASELINE) + '.png', dpi=savefig_dpi)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd1d97-ba0f-4413-99e5-4c2ebdff4cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "_main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
